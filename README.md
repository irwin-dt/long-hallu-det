# 📜 Long Context Hallucination Detection
## 🤔 Problem
To determine if a LLM is hallucinating in terms of faithfulness to a given long context. 𓂃✍︎
<br>
The team considers questions containing a long context that may include multiple documents 📖📑📓📕📋📝, and demonstrate across models that their solution can detect any hallucination in the answer that deviates from the context. 🤖🧠

_* Please read `generation.py/generation.ipynb` for more details on how the answers are generated._

## 💾 Installation
1) Install `uv` to manage packages
   
        curl -LsSf https://astral.sh/uv/install.sh | sh
   
2) Clone this repository

        git clone https://github.com/irwin-dt/long-hallu-det.git
        cd long-hallu-det

3) Install dependencies from `requirements.txt` and `flash-attn`

        uv venv
        source .venv/bin/activate
        uv pip install -r requirements.txt --cache-dir "/home/team/long-hallu-det/.cache/" && uv pip install flash-attn --no-build-isolation --cache-dir "/home/team/long-hallu-det/.cache/"
        deactivate
<br>

## 🔬 Testing
1) Download model of your choice from `huggingface`
   
        uv run hf download <huggingface_repo/model> --local-dir /home/team/models/<huggingface_repo/model>

2) Create your own collection of test documents and prepare your questions in `.csv` format (see `dummy_files` and `dummy_questions.csv`)

        # add your documents in .txt format to create a long-context
        mkdir documents
   
3) Run inference using `generation.py`
 
        # replace the model_path in config.yaml
        uv run python generation.py --config config.yaml    
<br>

⚠️ Important Information for scoring
* Your solution should be model agnostic. *- Practicality/Scalability (30%)* 🔧
* Input to your solution is *question+context+answer*; output is *yes/no*; explanation will be a **bonus** *- Innovation/Novelty (30%)* 💡
* For *Performance (30%)* evaluation, we will choose a **small, competetive model** that can handle context length of **at least 128k tokens**. ⚡
* Prepare a 10 minutes presentation + 5 minutes Q&A to show the judges the fruits of your labour!  *- Presentation (10%)* 🔎

## 📤 Submission
1) Download the model to be used for final testing (to be announced on Day 2). ☑️
* In `evaluation.py/evaluation.ipynb`
2) Concatenate the `test_documents` and read `test_set.csv` (to be provided on Day 2). ☑️
3) Fill in your preferred detection solution. ☑️
4) Show us your `accuracy score:` generated by the `evaluation.py/evaluation.ipynb` script. ☑️

Happy Hacking! 💻
